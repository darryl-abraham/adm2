{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mode</th>\n",
       "      <th>explicit</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975633</td>\n",
       "      <td>-0.730859</td>\n",
       "      <td>-0.845908</td>\n",
       "      <td>-1.889980</td>\n",
       "      <td>-1.784744</td>\n",
       "      <td>-0.078993</td>\n",
       "      <td>1.831732</td>\n",
       "      <td>-0.504094</td>\n",
       "      <td>-0.591211</td>\n",
       "      <td>-0.798690</td>\n",
       "      <td>-1.489717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.065299</td>\n",
       "      <td>-0.160332</td>\n",
       "      <td>-0.742186</td>\n",
       "      <td>-1.122669</td>\n",
       "      <td>-0.293288</td>\n",
       "      <td>-0.273826</td>\n",
       "      <td>-0.315499</td>\n",
       "      <td>-0.504112</td>\n",
       "      <td>-0.507167</td>\n",
       "      <td>-1.365688</td>\n",
       "      <td>-1.528312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.692961</td>\n",
       "      <td>-0.243214</td>\n",
       "      <td>-1.733304</td>\n",
       "      <td>-2.312994</td>\n",
       "      <td>-2.039252</td>\n",
       "      <td>-0.457309</td>\n",
       "      <td>1.774593</td>\n",
       "      <td>-0.503883</td>\n",
       "      <td>-0.428376</td>\n",
       "      <td>-1.276974</td>\n",
       "      <td>1.987859</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  danceability    energy  loudness  speechiness  \\\n",
       "0    0.975633    -0.730859     -0.845908 -1.889980 -1.784744    -0.078993   \n",
       "1    1.065299    -0.160332     -0.742186 -1.122669 -0.293288    -0.273826   \n",
       "2    1.692961    -0.243214     -1.733304 -2.312994 -2.039252    -0.457309   \n",
       "\n",
       "   acousticness  instrumentalness  liveness   valence     tempo  mode  \\\n",
       "0      1.831732         -0.504094 -0.591211 -0.798690 -1.489717     1   \n",
       "1     -0.315499         -0.504112 -0.507167 -1.365688 -1.528312     1   \n",
       "2      1.774593         -0.503883 -0.428376 -1.276974  1.987859     1   \n",
       "\n",
       "   explicit  time_signature  key  \n",
       "0         0               4    1  \n",
       "1         0               4    0  \n",
       "2         0               3    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/preprocessed_data.csv')\n",
    "\n",
    "X = df.drop(columns=['track_genre', \n",
    "                     'track_id', \n",
    "                     'track_name', \n",
    "                     'artists',\n",
    "                     'album_name'], \n",
    "            axis=1)\n",
    "X['explicit'] = X['explicit'].astype(int)\n",
    "y = df['track_genre']\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators_range = [50, 100, 150]\n",
    "max_depth_range = [10, 20, 30]\n",
    "criterion_range = ['gini', 'entropy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50, max_depth: 10, criterion: gini,\n",
      " mean_score: 0.29844990453220777\n",
      "n_estimators: 50, max_depth: 10, criterion: entropy,\n",
      " mean_score: 0.3056099889458346\n",
      "n_estimators: 50, max_depth: 20, criterion: gini,\n",
      " mean_score: 0.3282082202793689\n",
      "n_estimators: 50, max_depth: 20, criterion: entropy,\n",
      " mean_score: 0.31680233142397746\n",
      "n_estimators: 50, max_depth: 30, criterion: gini,\n",
      " mean_score: 0.3267887649482464\n",
      "n_estimators: 50, max_depth: 30, criterion: entropy,\n",
      " mean_score: 0.31779469400060295\n",
      "n_estimators: 100, max_depth: 10, criterion: gini,\n",
      " mean_score: 0.3041905336147121\n",
      "n_estimators: 100, max_depth: 10, criterion: entropy,\n",
      " mean_score: 0.31104914078987034\n",
      "n_estimators: 100, max_depth: 20, criterion: gini,\n",
      " mean_score: 0.33677519847251536\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = {'n_estimators': None, 'max_depth': None, 'criterion': None}\n",
    "\n",
    "# Perform hyperparameter optimization using four-fold cross-validation on the training set\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        for criterion in criterion_range:    \n",
    "            # Create the Random Forest model with the current hyperparameters\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion, random_state=42)\n",
    "\n",
    "            # Perform four-fold cross-validation on the training data and compute the mean score\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=4)\n",
    "            mean_score = scores.mean()\n",
    "\n",
    "            # Print the current hyperparameters and their corresponding mean score\n",
    "            print(f'n_estimators: {n_estimators}, max_depth: {max_depth}, criterion: {criterion},\\n mean_score: {mean_score}')\n",
    "\n",
    "            # Update the best parameters and score if the current score is better\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_params['n_estimators'], best_params['max_depth'], best_params['criterion'] = n_estimators, max_depth, criterion\n",
    "    # Print the best parameters and the best score\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "print(f'Best score: {best_score}')\n",
    "\n",
    "# Train the final model with the best hyperparameters on the entire training set\n",
    "final_model_RF = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                     max_depth=best_params['max_depth'],\n",
    "                                     criterion=best_params['criterion'],\n",
    "                                     random_state=42)\n",
    "final_model_RF.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred_RF = final_model_RF.predict(X_test)\n",
    "\n",
    "test_score_RF = accuracy_score(X_test, y_pred_RF)\n",
    "\n",
    "print(f'Test set score: {test_score_RF}')\n",
    "\n",
    "# Save the final model to a file using pickle\n",
    "with open('final_model_RF.pkl', 'wb') as file:\n",
    "    pickle.dump(final_model_RF, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes_range = [(50,), (100,), (30,30)]\n",
    "activation_range = ['logistic', 'tanh', 'relu']\n",
    "learning_rate_init_range = ['sgd', 'adam']\n",
    "\n",
    "# Initialize variables to store the best parameters and the best score\n",
    "best_score = 0\n",
    "best_params = {'hidden_layer_sizes': None, 'activation': None, 'learning_rate_init': None}\n",
    "\n",
    "# Perform hyperparameter optimization using four-fold cross-validation on the training set\n",
    "for hidden_layer_sizes in hidden_layer_sizes_range:\n",
    "    for activation in activation_range:\n",
    "        for learning_rate_init in learning_rate_init_range:\n",
    "            # Create the MLPClassifier model with the current hyperparameters\n",
    "            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, learning_rate_init=learning_rate_init, random_state=42)\n",
    "\n",
    "            # Perform four-fold cross-validation on the training data and compute the mean score\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=4)\n",
    "            mean_score = scores.mean()\n",
    "\n",
    "            # Print the current hyperparameters and their corresponding mean score\n",
    "            print(f'hidden_layer_sizes: {hidden_layer_sizes}, activation: {activation}, learning_rate_init: {learning_rate_init}, mean_score: {mean_score}')\n",
    "\n",
    "            # Update the best parameters and score if the current score is better\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_params['hidden_layer_sizes'] = hidden_layer_sizes\n",
    "                best_params['activation'] = activation\n",
    "                best_params['learning_rate_init'] = learning_rate_init\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "print(f'Best score: {best_score}')\n",
    "\n",
    "# Train the final model with the best hyperparameters on the entire training set\n",
    "final_model_MLP = MLPClassifier(hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "                                activation=best_params['activation'],\n",
    "                                learning_rate_init=best_params['learning_rate_init'],\n",
    "                                random_state=42)\n",
    "final_model_MLP.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred_MLP = final_model_MLP.predict(X_test)\n",
    "\n",
    "test_score_MLP = accuracy_score(y_test, y_pred_MLP)\n",
    "\n",
    "print(f'Test set score: {test_score_MLP}')\n",
    "\n",
    "# Save the final model to a file using pickle\n",
    "with open('final_model_MLP.pkl', 'wb') as file:\n",
    "    pickle.dump(final_model_MLP, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
